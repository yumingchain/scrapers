{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Import specific modules from libraries\n",
    "import asyncio\n",
    "from playwright.async_api import async_playwright, TimeoutError, Page\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from datetime import datetime\n",
    "from rich.console import Console\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "URL = 'https://www.founderspodcast.com/'\n",
    "\n",
    "# Initializing console for logging\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the scraper class\n",
    "class FoundersScraper:\n",
    "    async def initialize_browser(self):\n",
    "\n",
    "        def extract_date_and_episode(input_string):\n",
    "            # Regular expression pattern to match the date and episode number\n",
    "            pattern = r\"([A-Z]+ \\d+TH, \\d{4}) \\| E(\\d+)\"\n",
    "            match = re.search(pattern, input_string)\n",
    "            \n",
    "            if match:\n",
    "                date = match.group(1)\n",
    "                episode_number = match.group(2)\n",
    "                return date, episode_number\n",
    "            else:\n",
    "                # Return None if the pattern does not match\n",
    "                return None, None\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            console.log(\"Initialization of Browser...\")\n",
    "            self.playwright = await async_playwright().start()\n",
    "            self.browser = await self.playwright.chromium.launch(headless=False)\n",
    "            self.context = await self.browser.new_context()\n",
    "            self.page = await self.context.new_page()\n",
    "            await self.page.goto(URL)\n",
    "\n",
    "            list_selector = \"div.q-list > div > div\"\n",
    "\n",
    "            await self.page.wait_for_selector(list_selector)\n",
    "\n",
    "            episode_list = await self.page.query_selector_all(list_selector)\n",
    "\n",
    "            current_index: int = 0\n",
    "            visited = set()\n",
    "            page_number = 1\n",
    "            new_url = URL + f\"?prod-episode-release-desc%5Bpage%5D={page_number}\"\n",
    "\n",
    "            while current_index <= len(episode_list):\n",
    "\n",
    "                await self.page.wait_for_selector(list_selector)\n",
    "                episode_list = await self.page.query_selector_all(list_selector)\n",
    "\n",
    "                # console.log(\"finding episode\")\n",
    "\n",
    "                # console.log(\"episode_list length: \", len(episode_list), \"current_index: \", current_index)\n",
    "\n",
    "                episode = episode_list[current_index]\n",
    "                \n",
    "                await episode.wait_for_element_state(\"visible\")\n",
    "                await episode.click()\n",
    "                \n",
    "                # console.log(\"Clicked on the episode\")\n",
    "                # time.sleep(1)\n",
    "\n",
    "\n",
    "                # Get the data from the episode page\n",
    "                episode_name = await self.page.inner_text(\"#q-app > div > div > main > div > div.col-12.col-sm-12.col-md-10 > div > div.col-12.col-sm-10.q-pl-sm.q-py-md > div.q-pt-sm > span\")\n",
    "                # console.log(f\"episode_name: {episode_name}\")\n",
    "\n",
    "                if episode_name in visited:\n",
    "                    current_index += 1\n",
    "                    break\n",
    "                else:   \n",
    "                    date_and_epidode_number = await self.page.inner_text(\"#q-app > div > div > main > div > div.col-12.col-sm-12.col-md-10 > div > div.col-12.col-sm-10.q-pl-sm.q-py-md > div:nth-child(3) > span\")\n",
    "                    date, episode_number = extract_date_and_episode(date_and_epidode_number)\n",
    "                    # console.log(f\"date: {date}, episode_number: {episode_number}\")\n",
    "\n",
    "                    \n",
    "                    page_url = self.page.url\n",
    "                    # console.log(f\"page_url: {page_url}\")\n",
    "\n",
    "                    apple_url = await self.page.get_attribute(\"#q-app > div > div > main > div > div.col-12.col-sm-12.col-md-10 > div > div.col-12.col-sm-10.q-pl-sm.q-py-md > div.q-px-sm > div > div:nth-child(2) > a\", \"href\")\n",
    "                    # console.log(f\"apple_url: {apple_url}\")\n",
    "                                                        \n",
    "                    spotify_url = await self.page.get_attribute(\"#q-app > div > div > main > div > div.col-12.col-sm-12.col-md-10 > div > div.col-12.col-sm-10.q-pl-sm.q-py-md > div.q-px-sm > div > div:nth-child(3) > a\", \"href\")\n",
    "                    # console.log(f\"spotify_url: {spotify_url}\")\n",
    "                    \n",
    "\n",
    "                    episode_dict = {\n",
    "                        \"episode_name\": episode_name,\n",
    "                        \"description\": \"\",\n",
    "                        \"episode_id\":\"\",\n",
    "                        \"episode_number\": episode_number,\n",
    "                        \"episode_date\": date,\n",
    "                        \n",
    "                        \"page_url\": page_url,\n",
    "                        \"youtube_url\": \"\",\n",
    "                        \"apple_url\": apple_url,\n",
    "                        \"spotify_url\": spotify_url,\n",
    "                    }\n",
    "                    # print(episode_dict)\n",
    "                    console.log(episode_dict)   \n",
    "                    \n",
    "                if current_index == len(episode_list) - 1:\n",
    "                    current_index = 0\n",
    "                    page_number += 1\n",
    "                else:\n",
    "                    current_index += 1\n",
    "                new_url = URL + f\"?prod-episode-release-desc%5Bpage%5D={page_number}\"\n",
    "                await self.page.goto(new_url)\n",
    "                    \n",
    "                visited.add(episode_name)\n",
    "\n",
    "        \n",
    "        except Exception as e:\n",
    "            console.log(f\"Error during browser initialization: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    async def scrape(self):\n",
    "        try:\n",
    "            await self.initialize_browser()\n",
    "        except Exception as e:\n",
    "            console.log(f\"Error during scraping: {e}\")\n",
    "        finally:\n",
    "            if hasattr(self, 'browser'):\n",
    "                await self.browser.close()\n",
    "            if hasattr(self, 'playwright'):\n",
    "                await self.playwright.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    scraper = FoundersScraper()\n",
    "    asyncio.run(scraper.scrape())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
